from dotenv import load_dotenv
load_dotenv()
from openai import OpenAI
import streamlit as st
import tempfile
import os
from pathlib import Path
import mimetypes
import glob
# Check for OpenCV availability
try:
    import cv2
    have_cv2 = True
except ModuleNotFoundError:
    have_cv2 = False
    cv2 = None

import base64

# --- AUTENTICACI√ìN SIMPLE ---
PASSWORD = "SECRETMEDIA"
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False
if not st.session_state.authenticated:
    pw = st.text_input("Enter your super-ultra secret password (v24/06/2025 09:40h)", type="password")
    if pw == PASSWORD:
        st.session_state.authenticated = True
        st.rerun()
    else:
        st.stop()

client = OpenAI()

# --- CONFIGURACI√ìN DE LA P√ÅGINA ---
st.set_page_config(page_title="STAGING Convert Video into Text")
st.title("STAGINGüìù Video > Text AI Converter for SMN")

# --- CARGA DE PROMPTS EXTERNOS ---
def load_prompt(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return file.read()

sites = {
    "Valencia Secreta": load_prompt("prompts/sites/valencia_secreta.txt"),
    "Barcelona Secreta": load_prompt("prompts/sites/barcelona_secreta.txt"),
    "Madrid Secreto": load_prompt("prompts/sites/madrid_secreto.txt"),
    "New York City": load_prompt("prompts/sites/nyc_secret.txt"),
    "EXPERIMENTAL JAKUB": load_prompt("prompts/sites/experimental.txt")
}

editors = {
    "√Ålvaro Llagunes": load_prompt("prompts/editors/alvaro_llagunes.txt"),
    "Jorge L√≥pez Torrecilla": load_prompt("prompts/editors/jorge_lopez.txt"),
    "Alberto del Castillo": load_prompt("prompts/editors/alberto_del_castillo.txt")
}

categories = {
    "Gastronomy (restaurants, bars, street food)": load_prompt("prompts/category/food.txt"),
    "Sports for Secret Media": load_prompt("prompts/category/sports-smn.txt"),
    "Housing situation in big cities": load_prompt("prompts/category/problemas-vivienda.txt"),
    "Generic (use with caution)": load_prompt("prompts/category/generic.txt")
}

languages = {
    "English for US": load_prompt("prompts/languages/en-us.txt"),
    "Espa√±ol para Espa√±a": load_prompt("prompts/languages/es-sp.txt")
}

# --- SELECCI√ìN DE TIPO DE SUBIDA ---
upload_type = st.radio("What do you want to upload?", ["Video", "Image"], horizontal=True)
video_file = None
image_file = None
is_smn_video = True
visual_analysis = False
frame_interval = 1

if upload_type == "Video":
    video_file = st.file_uploader(
        "Upload your video (.mp4, .mov, .avi, .mp3, .wav, .ogg, .webm):",
        type=["mp4","mov","avi","mpeg","mp3","wav","ogg","webm"]
    )
    is_smn = st.radio("Is this an SMN-owned video?", ["Yes","No"], horizontal=True, key="is_smn")
    is_smn_video = is_smn == "Yes"
    visual_analysis = st.checkbox("Enable frame-by-frame visual analysis", key="visual_analysis")
    if visual_analysis:
        frame_interval = st.slider("Extract one frame every N seconds", 1, 10, 1, key="frame_interval")
elif upload_type == "Image":
    image_file = st.file_uploader(
        "Upload an image (.jpg,.jpeg,.png):",
        type=["jpg","jpeg","png"]
    )

# --- PROCESAMIENTO DE V√çDEO ---
if video_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(video_file.name).suffix) as tmp:
        tmp.write(video_file.read())
        tmp_path = tmp.name
    st.info(f"File size: {os.path.getsize(tmp_path)} bytes")
    mime_type, _ = mimetypes.guess_type(tmp_path)
    if not mime_type or not (mime_type.startswith("video") or mime_type.startswith("audio")):
        st.error("‚ùå Invalid file format for Whisper.")
        os.remove(tmp_path)
        st.stop()

# --- PROCESAMIENTO DE IMAGEN ---
elif image_file:
    if "image_description" not in st.session_state:
        image_bytes = image_file.read()
        b64 = base64.b64encode(image_bytes).decode("utf-8")
        st.session_state.b64_image = b64
        with st.spinner("üß† Analyzing image with GPT-4o..."):
            resp = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role":"user","content":[
                        {"type":"text","text":"Describe this image in detail. Focus on visual details, place, objects, text if any."},
                        {"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{b64}"}}
                    ]}
                ],
                max_tokens=800
            )
        st.session_state.image_description = resp.choices[0].message.content
        st.success("‚úÖ Image description generated")
elif upload_type == "Image":
    st.info("üì∏ Please upload an image to continue.")

# --- PREVIEW DE IMAGEN ---
if "image_description" in st.session_state:
    st.text_area("üñº Description of the image:", st.session_state.image_description, height=200, key="image_desc_preview")

# --- METADATOS NO SMN ---
tmp_extra_video = ""
network = username = original_url = ""
if upload_type == "Video" and not is_smn_video and video_file:
    network = st.selectbox("Social network:", ["YouTube", "TikTok", "Instagram", "Facebook", "Twitter", "Other"], key="video_network")
    username = st.text_input("Account (example: @user123):", key="video_username")
    original_url = st.text_input("URL of the video:", key="video_url")
    tmp_extra_video = st.text_area("(Optional) Extra instructions for this non-SMN video (use as much context as you want):", height=100, key="extra_video_prompt")

# --- CONFIGURACI√ìN DEL ART√çCULO ---
editor = st.selectbox("Editor:", ["Select...", *editors.keys()])
site = st.selectbox("Publish site:", ["Select...", *sites.keys()])
category_key = st.selectbox("Content category:", ["Select...", *categories.keys()])
language_key = st.selectbox("Output language:", ["Select...", *languages.keys()])
extra_prompt = ""
if site != "Select...":
    extra_prompt = st.text_area("Additional editor instructions (optional):")

# --- GENERAR ART√çCULO ---
if st.button("‚úçÔ∏è Create article"):
    try:
        # 1. Transcripci√≥n y an√°lisis visual
        if upload_type == "Video":
            transcription = ""
            visual_context = ""
            if visual_analysis:
                cap = cv2.VideoCapture(tmp_path)
                fps = cap.get(cv2.CAP_PROP_FPS) or 25
                frame_count = 0
                success, frame = cap.read()
                while success:
                    if frame_count % int(fps * frame_interval) == 0:
                        _, buffer = cv2.imencode('.jpg', frame)
                        b64_frame = base64.b64encode(buffer).decode("utf-8")
                        resp = client.chat.completions.create(
                            model="gpt-4o",
                            messages=[
                                {"role":"user","content":[
                                    {"type":"text","text":"Describe visual elements in this frame."},
                                    {"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{b64_frame}"}}
                                ]}
                            ],
                            max_tokens=150
                        )
                        visual_context += resp.choices[0].message.content + "\n"
                    success, frame = cap.read()
                    frame_count += 1
                cap.release()
            with st.spinner("‚è≥ Transcribing audio with Whisper..."):
                with open(tmp_path, "rb") as audio_f:
                    tr = client.audio.transcriptions.create(
                        model="whisper-1", file=audio_f, response_format="json"
                    )
                transcription = tr.text
            st.success("‚úÖ Transcription completed")
            st.text_area("Transcribed text:", transcription, height=200, key="video_text")
            if visual_analysis:
                st.text_area("Visual context:", visual_context, height=200, key="visual_context")
        elif upload_type == "Image" and "image_description" in st.session_state:
            transcription = st.session_state.image_description
            st.text_area("Image description:", transcription, height=200, key="image_text_area")
        else:
            st.error("‚ùå Upload a valid video or wait for image description.")
            st.stop()

        # 2. Construir prompt
        full_prompt = sites[site]
        if editor != "Select...":
            full_prompt += "\n\nEditor context:\n" + editors[editor]
        full_prompt += "\n\nTranscription for article:\n" + transcription
        if upload_type == "Video" and not is_smn_video:
            full_prompt += "\n\nNon-SMN video instructions:\n" + tmp_extra_video
            full_prompt += f"\nSource network: {network}"
            full_prompt += f"\nOriginal account: {username}"
            full_prompt += f"\nOriginal URL: {original_url}"
        if upload_type == "Video" and visual_analysis:
            full_prompt += "\n\nExtracted visual context:\n" + visual_context
        if category_key != "Select...":
            full_prompt += "\n\nCategory context:\n" + categories[category_key]
        if language_key != "Select...":
            full_prompt += "\n\nLanguage for article:\n" + languages[language_key]
        if extra_prompt:
            full_prompt += "\n\nAdditional editor instructions:\n" + extra_prompt

        # 3. Generar art√≠culo
        with st.spinner("üß† Generating article..."):
            resp = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role":"system","content":"Eres un redactor profesional..."},{"role":"user","content":full_prompt}],
                temperature=0.7
            )
        article = resp.choices[0].message.content

        # 4. Mostrar art√≠culo
        st.info(f"üìù Words: {len(article.split())}")
        st.success("‚úÖ Article ready")
        st.subheader("üîé Article:")
        st.markdown(article, unsafe_allow_html=True)
        # ... Discover, HTML/MD preview, download ...

    except Exception as e:
        st.error(f"‚ùå Error: {e}")
    finally:
        if upload_type == "Video" and 'tmp_path' in locals() and os.path.exists(tmp_path):
            os.remove(tmp_path)
